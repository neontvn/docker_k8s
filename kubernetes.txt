Docker Terminology

Kubernetes Terminology

1. Kubernetes Cluster - collection of nodes
2. Node - Virtual machine that will run code
3. Pods - Running container. Technically a pod can run multiple containers
4. Deployment - Monitors a set of pods, makes sure they are running and restarts if crashed
5. Service - Provides an easy to remember URL to access a running container

Kubernetes Config Files
 - Tells Kubernetes about the Deployments, Pods, Services ( Referred to as Objects )
 - Written in YAML syntax
 - Documentation

Minikube : 

    --> Minikube runs a single-node Kubernetes cluster on your personal computer
    --> A one node cluster, where the master and worker processes are on the same machine.

Commands
    |_ minikube start
    |_ minikube dashboard
___________________________________________________________________________________________

Creating a Pod ( With example and explaination )

File - posts.yaml

apiVersion : v1
kind : Pod              // Type of Object we want to create
metadata :
    name : posts        // pod is given name of posts
spec :                  // Exact attributes  we want to apply to the object
    containers:         // We can create multiple containers inside a pod
        - name : posts                      // Container with name posts
          image : hungryshark/posts:0.0.1   // Image from which it is going to be created
          imagePullPolicy: IfNotPresent

kubectl apply -f posts.yaml     // To tell kubernetes to use this config file

kubectl get pods                        // Get information of the existing pods
kubectl exec -it [pod-name][command]    // Execute the given command in a running pod
kubectl logs [pod-name]                 // Prints out logs from the given pod
kubectl delete pod [pod-name]           // Delete the pod
kubectl apply -f [config file name]     // Tell k8s to process the config
kubectl describe pod [pod-name]         // Print out some information about the running pod
___________________________________________________________________________________________


DEPLOYMENTS

- Rather than creating individual pods we create a Deployment object which manages a set of k8s pods.
- Pod crashes, then deployment automatically creates the pods for us.
- Version of pods may change in due course of time. Deployment helps in managing the same.

CREATING A DEPLOYMENT

File - posts-depl.yaml

apiVersion : apps/v1
kind : Deployment               // Type of Object we want to create
metadata : 
    name : posts-depl           // Name of the deployment   
spec :                          // How deployment should behave
    replicas : 1                // Number of pods running a particular image
    selector :                  // Deployment gets to know which pods to manage
        matchLabels :
            app : posts         // Key : Value can be xyz : posts as well
    template :                  // Specify exact config of pod to be created
        metadata :
            labels:
                app : posts     // Key : value pair assigned same as above
        spec :                  // Config of pods
            containers :            // Container created in pod
                -   name : posts    // Container with name posts
                    image : hungryshark/posts:latest    // Image to be run in the container
                    
___________________________________________________________________________________________


kubectl apply -f [config file name]             // Create deployment out of config file
kubectl get deployments                         // Lists all the deployments
kubectl describe deployment [depl name]         // Print out details of specific deployment
kubectl delete deployment [depl-name]           // Delete a deployment

___________________________________________________________________________________________


Updating a deployment : Two ways to do it

First Method

1. Make a change to your project code
2. Rebuild the image, specifying a new image Version
3. In the deployment config file, update the version of the image
4. Run kubectl apply -f [depl file name]

Second Method ( Generally preferred )

1. The deployment must be using the 'latest' tag in the pod spec section
2. Make an update to the code
3. Build the image
4. Push the image to docker hub
5. Run the command :  kubectl rollout restart deployment [depl-name]

___________________________________________________________________________________________

SERVICES

Types of Services
    - Cluster IP - Set up an easy-to-remember URL to access a pod. Only exposes pods in the cluster
    - Node Port - Makes a pod accessible from outside the cluster. Usualy for dev purposes
    - Load Balancer - Makes a pod accessible from outside the cluster.
    - External Name - Redirects as in-cluster request to a CNAME URL


NodePort - File posts-srv.yaml

apiVersion : v1
kind : Service
metadata :
    name : posts-serv
spec:
    type : NodePort             // Object type
    selector:
        app : posts             // This service is applicable to this app
    ports :
        - name : posts          // Details of the port
          protocol : TCP
          port : 4000           // Port number of Node Port Service
          targetPort : 4000     // Port number of where the posts app is served ( mentioned in posts/index.js )


kubectl apply -f posts-srv.yaml

Command - kubectl get services
Output - posts-serv   NodePort    10.105.8.62   <none>   4000:32536/TCP   8m27s

4000:32536/TCP - Here 32536 is the port at which the app is made accessible from outside the cluster

minikube ip - Gives the ip address of the minikube cluster
Generally, 192.x.x.x

Example, 192.168.44.2:32536/posts 

___________________________________________________________________________________________

CLUSTER IP Services

contd to the above file
---
apiVersion : v1
kind : Service
metadata : 
    name : posts-clusterip-srv
spec : 
    selector : 
        app : posts
    ports :
        - name : posts
          protocol : TCP
          port : 4000   
          targetPort : 4000

___________________________________________________________________________________________

The react app is set up in a pod as react app dev service which returns the HTML, JS, CSS back to the browser.

Now it is the browser which makes request for the actual data.

Option 1  : We can have NodePort for each pod which exposes the pod to external through a random port which may change sometime
            in near future. Therefore it is a very inefficient way of doing the same.
Option 2  : Rather than exposing all the pods we can a load balancer service which gives a single point of entry to the cluster
            LBS takes the request and routes to the particular port.


Load Balancer and Ingress

Load Balancer Service : Tell Kubernetes to reach out to its provider and provision a load balancer.
                        Gets traffic to a single pod
Ingress : A pod with set of routing rules to distribute traffic to other services.

So we have ingress/ ingress controller ( used here interchangably in this scenario ) which has the specific rules written 
to set the routing to a particular pod.

___________________________________________________________________________________________

ingress-nginx : Open source library that will create a Load Balancer Service + an Ingress for the user.

To add ingress controller to minikube use the following command : 
    $ minikube addons enable ingress

Now that we have the ingress controller in our cluster, there is a need to specify the routing rules.
Config file contains the router rules.

Config File ( ingress-srv.yaml )
___________________________________________________________________________________________

apiVersion : networking.k8s.io/v1beta1
kind : Ingress
metadata : 
  name : ingress-srv
  annotations:                              // This section tells the ingress-controller that we are trying to feed it some routing rules. 
    kubernetes.io/ingress.class : nginx     // ingress-controller scans all the different objects / config files and tries to find the one 
                                            // with the mentioned annotation.
    nginx.ingress.kubernetes.io/use-regex : 'true' // For using regex 
spec : 
  rules:
    - host : posts.com                      // Hosting many different apps at different domains. Here we trick the computer to connect to 
      http :                                // our machine using the alias. Set {minikube ip} posts.com in /etc/hosts file. 
        paths: 
          - path : /posts                   // Route to the post microservice name on port 4000
            backend : 
              serviceName : posts-clusterip-srv     // We send it to the service and not the pod directly because the communication takes
              servicePort : 4000                    // place through the services only within the cluster
          - path : /posts
            backend : 
              serviceName : query-srv
              servicePort : 4002
          - path : /posts/?(.*)/comments
            backend : 
              serviceName : comments-srv
              servicePort : 4001
          - path : /?(.*)
            backend : 
              serviceName : client-srv
              servicePort : 3000
___________________________________________________________________________________________

Changing the url within the react app from localhost:400x to posts.com now enables these rules to be used and the 
react app is served from posts.com

Big issue : Rebuilding the entire image again and pushing to docker hub or for that matter updating the k8s files as well
manually is tedious task. So we use Scaffold.
___________________________________________________________________________________________

Scaffold : Skaffold handles the workflow for building, pushing and deploying your application, allowing you to focus on 
what matters most: writing code.

Installation Step:
    -> curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && \
        sudo install skaffold /usr/local/bin/

We create a skaffold config file outside our project/cluster.

skaffold.yaml:
___________________________________________________________________________________________

apiVersion : skaffold/v2alpha3
kind : Config
deploy :
  kubectl:
    manifests:
      - ./infra/k8s/*           // Folder which contains all the deployments
build :
  local : 
    push : false
  artifacts :
    - image : hungryshark/client    // Individual images of the different pods
      context : client
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : 'src/**/*.js'     // Look out for the src folder and subfolders for any changes if any just push into the pod
            dest : .                // Else just rebuild the image again if outside src folder
    - image : hungryshark/comments
      context : comments
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : '*.js'            // Here we are concerned with the .js file only
            dest : .
    - image : hungryshark/posts
      context : posts
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : '*.js'
            dest : .
    - image : hungryshark/query
      context : query
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : '*.js'
            dest : .
    - image : hungryshark/event-bus
      context : event-bus
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : '*.js'
            dest : .
    - image : hungryshark/moderation
      context : moderation
      docker:
        dockerfile : Dockerfile
      sync:
        manual:
          - src : '*.js'
            dest : .
___________________________________________________________________________________________

 - Once this is done all we have to do is to run : skaffold dev
 - This creates objects which are required for the application and detects for any changes inside the project/cluster.
 - Once we exit the skaffold dev using Ctrl + C. All the deployments are DELETED and thereby no resources are left once we
   exit the skaffold.
 - This enables easy switching between the projects without actually bothering to delete the deployments manually

___________________________________________________________________________________________